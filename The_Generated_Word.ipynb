{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "The Generated Word.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexgshaw/vol3project2/blob/main/The_Generated_Word.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LW1zM_R88ig"
      },
      "source": [
        "Grant White, Johnson Merrell, Walker Hughes, Alex Shaw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYgq8VH08tBb"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Can we train a computer to write new church hymns? Our project is seeking to answer this question. We will be attempting to recreate both lyrics and music. In this draft we focus on text generation. \n",
        "\n",
        "Text generation has become a hot topic in the past decade, and has begun seeing great success in recent years. Applying these methods to song generation will be a new aspect to explore. Music generation has not seen the same amount of success as text generation, but is still an active field of research."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR_ZnKQz95cQ"
      },
      "source": [
        "# Data Cleaning\n",
        "\n",
        "We will use the lyrics from all the Hymns of the Church of Jesus Christ of Latter-day Saints as well as the instrumental tracks. Both of these are available at www.churchofjesuschrist.org. There are 341 hymns available in English.\n",
        "\n",
        "The first step will be processing our data. This will be done in the following five steps:\n",
        "\n",
        "1. Scrape data from online.\n",
        "1. Split each word into it's own line.\n",
        "1. Remove verse numbers.\n",
        "1. Replace sentence-ending punctuation and end of songs with stop words.\n",
        "1. Remove all remaining punctuation.\n",
        "\n",
        "The code for web scraping and data cleaning is given below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8lGeWqWUzgg"
      },
      "source": [
        "#initialize url\n",
        "url = 'https://www.churchofjesuschrist.org'\n",
        "hymn = '/study/manual/hymns/the-morning-breaks?lang=eng'\n",
        "\n",
        "#open file\n",
        "with open('lyrics.txt', 'a') as file:\n",
        "    for i in range(341):\n",
        "        # get html code\n",
        "        page_source = requests.get(url + hymn).text\n",
        "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
        " \n",
        "        # print hymn number\n",
        "        print(soup.find(class_='title-number').string)\n",
        "\n",
        "        # get text\n",
        "        current = soup.find_all(class_=\"stanza\")\n",
        "        for verse in current:\n",
        "            lines = verse.strings\n",
        "            for line in lines:\n",
        "                file.write(line + '\\n')\n",
        "            \n",
        "        # update url\n",
        "        if i < 340:\n",
        "            hymn = soup.find(class_='traversalLink-1QVq2 nextLink-1V6GZ').a['href']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TGMuNc08mmx"
      },
      "source": [
        "# Read in our file of lyrics (all songs from the hymn book)\n",
        "filename = 'lyrics.txt'\n",
        "with open(filename) as file:\n",
        "    lyrics = file.read().split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcACz7pOByIC"
      },
      "source": [
        "# Get rid of all the empty strings\n",
        "not_empty = lambda x: len(x) != 0\n",
        "lyrics = list(filter(not_empty, lyrics))\n",
        "\n",
        "# Replace '1.' with end of song word\n",
        "end_of_song = 'END'\n",
        "lyrics = [lyric if lyric != '1.' else end_of_song for lyric in lyrics]\n",
        "lyrics = lyrics[1:]\n",
        "lyrics.append(end_of_song)\n",
        "\n",
        "# Strip out all the verse numbers\n",
        "not_verse_num = lambda x: not (x[0].isnumeric() and x.endswith('.'))\n",
        "lyrics = list(filter(not_verse_num, lyrics))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOPtH2WEB066"
      },
      "source": [
        "# Replace all periods with a stop word\n",
        "period = 'PERIOD'\n",
        "exclamation = 'EXCLAMATION'\n",
        "question = 'QUESTION'\n",
        "semi_colon = 'SEMI'\n",
        "\n",
        "stop_lyrics = []\n",
        "\n",
        "for lyric in lyrics:\n",
        "    if lyric.endswith('.'):\n",
        "        lyric = lyric.replace('.', '')\n",
        "        stop_lyrics.append(lyric)\n",
        "        stop_lyrics.append(period)\n",
        "    elif lyric.endswith(';'):\n",
        "        lyric = lyric.replace(';', '')\n",
        "        stop_lyrics.append(lyric)\n",
        "        stop_lyrics.append(semi_colon)\n",
        "    elif lyric.endswith('!'):\n",
        "        lyric = lyric.replace('!', '')\n",
        "        stop_lyrics.append(lyric)\n",
        "        stop_lyrics.append(exclamation)\n",
        "    elif lyric.endswith('?'):\n",
        "        lyric = lyric.replace('?', '')\n",
        "        stop_lyrics.append(lyric)\n",
        "        stop_lyrics.append(question)\n",
        "    else:\n",
        "        stop_lyrics.append(lyric)\n",
        "\n",
        "lyrics = stop_lyrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MVzAPGQB4v0"
      },
      "source": [
        "def process_lyric(lyric):\n",
        "    \"\"\"\n",
        "    Gets rid of punctuation and non-latin characters\n",
        "    \"\"\"\n",
        "    apostrophe = 'â\\x80\\x99'\n",
        "    a_hat = 'â'\n",
        "    lyric = lyric.replace(apostrophe, '')\n",
        "    lyric = lyric.replace(a_hat, '') \n",
        "    lyric = ''.join([char for char in lyric if char.isalpha()])\n",
        "\n",
        "    return lyric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5lxLXpSB8kI"
      },
      "source": [
        "# Get rid of punctuation and non-latin characters\n",
        "lyrics = list(map(process_lyric, lyrics))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFUGW8FWB-rV"
      },
      "source": [
        "# Write the cleaned lyrics\n",
        "filename = 'clean_lyrics.txt'\n",
        "with open(filename, 'w') as file:\n",
        "    for lyric in lyrics:\n",
        "        lyric += '\\n'\n",
        "        file.write(lyric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zpKMubCEKD6"
      },
      "source": [
        "# Methods\n",
        "\n",
        "To produce a hymn we generate lyrics and music through distinct processes. For lyrics we use a Markov chain, transformer, and recurrent neural network (RNN). For music, we experiment with a traditional RNN and generative adversarial network (GAN).\n",
        "\n",
        "## Lyrics\n",
        "A Markov chain is a straightforward and obvious model to use for generating random text to resemble a given corpus. Markov chains are simple to implement, quick to train on small corpuses, and easy to explain to others. Unfortunately, these benefits come at a cost – because our model is _Markov_, it only takes into consideration one word or lyric at a time when predicting the next. We implemented our own model using a dictionary, with the key being a word or lyric, and the value being a list of non-unique words that follow the key in the corpus. We include this code below:\n",
        "\n",
        "```\n",
        "filename = 'clean_lyrics.txt'\n",
        "with open(filename) as file:\n",
        "    lyrics = file.read().split()\n",
        "\n",
        "for word1, word2 in pairs:\n",
        "    if word1 in word_dict.keys():\n",
        "        word_dict[word1].append(word2)\n",
        "    else:\n",
        "        word_dict[word1] = [word2]\n",
        "\n",
        "# Find all potential start words and pick a random one\n",
        "start_words = [word for word in lyrics if (word[0].upper() == word[0]) and word not in stop_words]\n",
        "\n",
        "stop_words = {\n",
        "    'PERIOD': '.',\n",
        "    'EXCLAMATION': '!',\n",
        "    'QUESTION': '?',\n",
        "    'SEMI': ';',\n",
        "    'END': '',\n",
        "}\n",
        "\n",
        "def generate_text(start_word):\n",
        "    \"\"\"Generates text.\"\"\"\n",
        "    sentence = [start_word]\n",
        "    word = start_word\n",
        "    while True:\n",
        "        word = np.random.choice(word_dict[word])\n",
        "        if word in stop_words:\n",
        "            sentence.append(stop_words[word])\n",
        "            if word == 'END':\n",
        "                break\n",
        "        else:\n",
        "            sentence.append(' ' + word)\n",
        "\n",
        "    return ''.join(sentence)\n",
        "\n",
        "start_word = np.random.choice(start_words)\n",
        "generate_text(start_word)\n",
        "```\n",
        "\n",
        "We also use a highly optimized package for constructing Markov chains for this exact use called `markovify`. This package makes it extremely easy to build and use Markov chains trained on small and medium-sized corpuses.\n",
        "\n",
        "```\n",
        "import markovify\n",
        "\n",
        "with open(\"./cleaned_lyrics.txt\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "text_model = markovify.Text(text)\n",
        "    \n",
        "print(text_model.make_short_sentence(100))\n",
        "```\n",
        "\n",
        "Note that the `.make_short_sentence(N)` method generates a sentence with `N` characters or less.\n",
        "\n",
        "## Music\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdvAUALITqgl"
      },
      "source": [
        "To generate hy  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}